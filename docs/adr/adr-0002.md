

# ADR-0002: Update to LLM Model and Pipeline Strategy

## Status
Accepted – 2025-08-15

## Context
The project previously relied on a specific LLM model with a Colab-based pipeline for downloading and converting models into GGUF format.  
As of 2025-08-11, a new lightweight multimodal LLM model, **jan-v1-4v** (4B parameters, quantized), has been released.  
This model is particularly suitable for iOS on-device inference due to its reduced size and optimized architecture.  
In addition, the GGUF acquisition process no longer needs to be exclusively performed through Colab; CLI-based direct download methods are now available and preferred for development flexibility.

## Decision
- Adopt **jan-v1-4v** as the primary LLM model for the RAGfish iOS application.
- Update the model acquisition pipeline to:
  - Support CLI-based direct downloads of GGUF files as the primary method.
  - Retain Colab-based acquisition as an optional fallback method.
- Ensure downstream components (tokenizer, embedding, RAG pipeline) remain compatible with jan-v1-4v.

## Consequences
- **Positive**:
  - Improved inference performance on iOS devices.
  - Reduced startup latency and memory usage.
  - Greater flexibility in model acquisition and development workflows.
- **Negative**:
  - Potential need for additional compatibility testing when updating the model.
  - Architecture diagrams (ARCHITECTURE.md) and UML sequence diagrams may require updates to reflect the new pipeline flow.

## References
- [jan-v1-4v model page](https://huggingface.co/janhq/jan-v1-4v)
- Project’s pipeline documentation (see `docs/pipeline.md`)