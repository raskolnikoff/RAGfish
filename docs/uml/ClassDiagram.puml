@startuml
!theme amiga
left to right direction

'=== Shared types / enums ===
enum Modality {
    text
    vision
}
enum ModelFormat {
    gguf
    transformers
    coreml
}
class PromptTemplate {
    +style: String
    +system_prefix: String
    +user_prefix: String
    +assistant_prefix: String
    +suffix: String
    +stop: String[*]
}

'=== iOS App Layer ===
class RAGApp {
    +DocumentManager documentManager
    +ModelManager modelManager
    +Settings settings
    +UserQuery ask(query): Answer
}

class DocumentManager {
    +importDocument(file)
    +loadFromGoogleDrive(file)
    +importModelResource(file)
    +ragpacks: RAGpack[*]
}

class RAGpack {
    +filename: String
    +metadata: Map
    +chunks: Chunk[*]
    +imageChunks: ImageChunk[*]  ' optional (vision)
    +isEmbedded: Bool
    +Note: Always imported/exported as .zip archive, not individual files.
    +Note: May include image embeddings when vision workflows are enabled.
}

class Chunk {
    +content: String
    +embedding: float[]
}

class ImageChunk {
    +imageId: String
    +embedding: float[]
    +meta: Map
}
note right of ImageChunk
Experimental for jan‑v1‑4v (vision). Only present when vision is enabled.
end note

class VectorStore {
    +textChunks: Chunk[*]
    +imageChunks: ImageChunk[*]
    +findRelevant(queryEmbedding, modality: Modality = text): (Chunk[*] | ImageChunk[*])
}

class UserQuery {
    +question: String
    +runQuery(): Answer
}

class AnswerGenerator {
    +generate(chunks: Chunk[*], query: String): Answer
}

class ModelManager {
    +currentEmbeddingModel: EmbeddingModel
    +currentLLMModel: LLMModel
    +switchEmbeddingModel(name)
    +switchLLMModel(name)
    +supportsVision(): Bool
}

class QAPair {
    +question: String
    +answer: String
    +timestamp: DateTime
}

'=== Settings manages only the essential configuration for the app. ===
class Settings {
    +selectedEmbeddingModelName: String
    +selectedLLMModelName: String
    +ragpackPath: String
    +modelResourcePath: String
    +theme: String
    +language: String
    +load()
    +save()
    +isUsingEmbeddedModel: Bool
    +isUsingEmbeddedRAGpack: Bool
    +useEmbeddedResources()
}
note right of Settings
App includes embedded default resources (LLMModel, RAGpack) for out-of-the-box usage.
Default on-device text model may be Jan‑v1‑4B (GGUF). Vision (jan‑v1‑4v) is optional.
Prompt formatting is metadata-driven (per model family / template).
Users may optionally import custom resources if needed.
end note

note right of QAPair
UI-level thread, history, and QA management is detailed in NoesisNoema implementation.
end note

'=== Model Pipeline Layer ===
class Preprocessor {
    +preprocess(document): Chunk[*]
    +preprocessImages(document): ImageChunk[*]   ' optional (vision)
}

class EmbeddingModel {
    +name: String
    +embed(text: String): float[]
}

class LLMModel {
    +name: String
    +modelFile: String
    +version: String
    +format: ModelFormat
    +modalities: Modality[*]
    +contextWindow: Int
    +promptTemplate: PromptTemplate
    +generate(prompt: String): String
    +supportsVision(): Bool
    +loadModel(file)
}
note right of LLMModel
Jan family (e.g., Jan‑v1‑4B/4v) uses Qwen‑style chat templates.
Vision (4v) is optional and enabled when model advertises modality = vision.
end note

class ChunkExporter {
    +export(chunks: Chunk[*]): RAGpack
}

'=== Storage / External Services ===
class GoogleDriveService {
    +upload(file)
    +download(filename)
    +listFiles()
}

class FileResource {
    +filename: String
    +data: Binary
}

'=== Admin ===
class SystemLog {
    +logEvent(event: String)
}

'=== Relations with multiplicity ===
DocumentManager "1" -- "0..*" RAGpack
RAGpack "1" -- "0..*" Chunk
RAGpack "1" -- "0..*" ImageChunk
RAGApp "1" -- "0..*" QAPair

'=== Relations ===
RAGApp --> DocumentManager
RAGApp --> ModelManager
RAGApp --> Settings
RAGApp --> UserQuery
DocumentManager --> RAGpack
RAGpack --> Chunk
DocumentManager --> GoogleDriveService
' Google Drive import is optional; local/CLI first
DocumentManager --> FileResource
DocumentManager --> LLMModel
UserQuery --> VectorStore
VectorStore --> Chunk
VectorStore --> ImageChunk
UserQuery --> AnswerGenerator
AnswerGenerator --> Chunk
ModelManager --> EmbeddingModel
ModelManager --> LLMModel
Preprocessor --> EmbeddingModel
Preprocessor --> Chunk
ChunkExporter --> RAGpack
GoogleDriveService --> FileResource

@enduml